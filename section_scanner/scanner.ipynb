{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_image(image_path, target_path):\n",
    "    shutil.copy(image_path, target_path)\n",
    "\n",
    "output_dir = './output/'\n",
    "input_dir = './image_input/'\n",
    "try:\n",
    "    os.makedirs('./output')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for image in os.listdir(input_dir):\n",
    "    image = \"\".join(image.split('.')[:-1:])\n",
    "\n",
    "    try:\n",
    "        os.makedirs(output_dir+image)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        copy_image(input_dir+image+'.png', output_dir+image+'/')\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT SIDEBAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sidebar ... ./output//input//sidebar/input\n",
      "Sidebar ... done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import shutil\n",
    "import json \n",
    "\n",
    "\n",
    "current_path = os.getcwd() \n",
    "\n",
    "output_path = \"./output/\"\n",
    "\n",
    "\n",
    "\n",
    "for name in os.listdir(output_path):\n",
    "    # only take the sidebar\n",
    "    current_image_path = output_path+'/'+name+'/'\n",
    "    output_dir = current_image_path + \"/sidebar/\"\n",
    "    input_image_path = current_image_path + name + '.png'\n",
    "    image = Image.open(input_image_path)\n",
    "    \n",
    "    # 1/7 is the sidebar part \n",
    "    image = image.crop((0,0,70,image.height)) #(1/6)\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(output_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(f'Sidebar ... {output_dir+name}')\n",
    "\n",
    "    image.save(output_dir+name+'.png')\n",
    "    print(f'Sidebar ... done')\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT SECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def overlay_squares_with_labels(original_img_path, squares, output_path):\n",
    "    \"\"\"\n",
    "    Overlays the detected black squares with a red box and labels the height of each square.\n",
    "    \n",
    "    Args:\n",
    "    original_img_path (str): Path to the original image.\n",
    "    squares (list of tuples): Each tuple contains (start_height, height) for each black square.\n",
    "    output_path (str): Path to store the result image.\n",
    "    \"\"\"\n",
    "    # Load the original image\n",
    "    img = Image.open(original_img_path)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Define the box color and text color\n",
    "    box_color = (255, 0, 0)  # Red color\n",
    "    text_color = (255, 0, 0) # Red text\n",
    "    \n",
    "    # Load a font for the height labels\n",
    "    # Using default font as PIL may not always have a specific font path on the system\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 15)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Get image width (to make the box span across the image width)\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    # Overlay each square with a red box and label it with its height\n",
    "    for start, height,x_min,x_max in squares:\n",
    "        # Draw a red rectangle around each black square\n",
    "        draw.rectangle([x_min, start, x_max, start + height], outline=box_color, width=2)\n",
    "        \n",
    "        # Add the height label next to the square\n",
    "        draw.text((img_width - 50, start - 15), f\"{start}px\", fill=text_color, font=font)\n",
    "    \n",
    "    # Save the resulting image\n",
    "    img.save(output_path)\n",
    "    # print(f\"Image saved at {output_path}\")\n",
    "\n",
    "# Example usage with the provided squares and a new output path\n",
    "\n",
    "def get_black_square_data(image,  min_size=15):\n",
    "    # Convert the image to grayscale to help detect the black squares\n",
    "    gray_img = image.convert('L')\n",
    "    gray_img.point(lambda x: 0 if x < 128 else 255, '1')\n",
    "    \n",
    "    # Convert the PIL image to a NumPy array\n",
    "    binary_image = np.array(gray_img.copy())\n",
    "\n",
    "    # Threshold the array to ensure it's binary\n",
    "    binary_image = (binary_image < 128).astype(int)  # Assuming black is below 128\n",
    "    \n",
    "    # Ensure the binary image is in the correct format\n",
    "    if binary_image.dtype != np.uint8:\n",
    "        binary_image = binary_image.astype(np.uint8)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_image =  image.copy()\n",
    "\n",
    "    # List to store rectangle properties\n",
    "    rectangles = []\n",
    "\n",
    "    # Iterate over contours\n",
    "    for contour in contours:\n",
    "        # Get the bounding box for each contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Check if the bounding box is a square and larger than 15x15\n",
    "        if w >= min_size and h >= min_size and abs(w - h) <= 2:  # Allow a small tolerance for non-perfect squares\n",
    "            # Append the rectangle properties: (start_height, height, x_min, x_max)\n",
    "            rectangles.append((y, h, x, x + w))\n",
    "            \n",
    "            draw = ImageDraw.Draw(contour_image)\n",
    "            contour_points = [(int(point[0][0]), int(point[0][1])) for point in contour]\n",
    "            draw.polygon(contour_points, outline=(0, 255, 0), width=2)\n",
    "            # contour_image = draw.polygon(contour, fill=(0,255,0))\n",
    "\n",
    "    \n",
    "    \n",
    "    return rectangles, gray_img, contour_image\n",
    "\n",
    "\n",
    "output_path = \"./output/\"\n",
    "\n",
    "for image_dir in os.listdir(output_path):\n",
    "    output_dir = output_path+image_dir + '/square_recognition/'\n",
    "    try:\n",
    "        os.makedirs(output_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Load the image\n",
    "    input_image_path = output_path+image_dir + '/sidebar/'+ image_dir + '.png'\n",
    "\n",
    "    img = Image.open(input_image_path)\n",
    "\n",
    "\n",
    "    # Get the heights and start positions of the black squares\n",
    "    black_square_info, gray_img, contour_image = get_black_square_data(img)\n",
    "    gray_img.save(output_dir+image_dir+'_bw.png')\n",
    "    contour_image.save(output_dir+image_dir+'_countors.png')\n",
    "    \n",
    "    # filter too high\n",
    "    black_square_info = [x for x in black_square_info if x[3] - x[2] > 10]\n",
    "\n",
    "    # sort\n",
    "    black_square_info.sort(key=lambda x: x[0])\n",
    "\n",
    "    with open(output_dir+image_dir+'.json', 'w') as f:\n",
    "        json.dump(black_square_info, f)\n",
    "    \n",
    "    overlay_squares_with_labels(input_image_path, black_square_info, output_dir+image_dir+'.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import shutil\n",
    "import json \n",
    "\n",
    "\n",
    "def clamp(n, min, max): \n",
    "    if n < min: \n",
    "        return min\n",
    "    elif n > max: \n",
    "        return max\n",
    "    else: \n",
    "        return n \n",
    "\n",
    "\n",
    "output_path = \"./output/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for name in os.listdir(output_path):\n",
    "    image_path = output_path+name+'/'+name+'.png'\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "\n",
    "    with open(output_path+name+'/square_recognition/'+name+'.json', 'r') as f:\n",
    "        square_data = json.load(f)    \n",
    "    \n",
    "    square_heights = [square[0] for square in square_data]\n",
    "    square_x_max = [square[3] for square in square_data]\n",
    "    square_heights.append(image.height)\n",
    "\n",
    "    for index, h_break in enumerate(square_heights):\n",
    "        \n",
    "        if (index >= len(square_heights) - 1 ):\n",
    "            continue\n",
    "        \n",
    "        y = clamp(h_break - 7, 0, image.height - 1)\n",
    "        next_y = clamp(square_heights[index+1] - 5, 0, image.height - 1)\n",
    "        \n",
    "        # min height and fix\n",
    "        if (next_y < y or next_y - y < 30):\n",
    "            continue\n",
    "        \n",
    "        # kantlijn, boven, einde van pagina, beneden grens\n",
    "        crop = (0, y, image.width, next_y)\n",
    "        \n",
    "        section_image = image.copy()\n",
    "        \n",
    "        cropped = section_image.crop(crop)        \n",
    "\n",
    "        # section_image.show()\n",
    "        # section_file_name = filenameify(h_break[\"description\"])+\".png\"\n",
    "        \n",
    "        output_dir = output_path + name + '/sections/' + str(index) + '/'\n",
    "        try:\n",
    "            os.makedirs(output_dir)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        section_name = name+\"_s\"+str(index)\n",
    "        cropped.save(output_dir+section_name+'.png')\n",
    "\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            os.makedirs(output_dir+'question_selection/')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        question_selection_crop = (square_x_max[index], 0, int(cropped.width * (1/8)), cropped.height)\n",
    "        question_selection_image = cropped.copy().crop(question_selection_crop)\n",
    "        question_selection_image.save(output_dir+'question_selection/'+section_name+'.png')\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(output_dir+'answer/')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        answer_crop = (int(cropped.width * (1/8) ), 0, cropped.width, cropped.height)\n",
    "        answer_image = cropped.copy().crop(answer_crop)\n",
    "\n",
    "        answer_image.save(output_dir+'answer/'+section_name+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting input\n",
      "Finished input\n",
      "Starting input\n",
      "Finished input\n",
      "Starting input\n",
      "Finished input\n",
      "Starting input\n",
      "Finished input\n",
      "Starting input\n",
      "Finished input\n",
      "Starting input\n",
      "Finished input\n",
      "Starting input\n",
      "Finished input\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "\n",
    "output_path = \"./output/\"\n",
    "\n",
    "\n",
    "with open(\"creds/microsoft.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    endpoint = data[\"endpoint\"]\n",
    "    credential = AzureKeyCredential(data[\"subscription_key\"])\n",
    "    document_intelligence_client = DocumentAnalysisClient(endpoint, credential)\n",
    "\n",
    "for name in os.listdir(output_path):\n",
    "    \n",
    "    for section in os.listdir(output_path+name+'/sections/'):\n",
    "        section_dir = output_path+name+'/sections/'+section+'/'\n",
    "        section_name = name+'_s'+section\n",
    "        input_dir = section_dir+'question_selection/'+section_name+'.png'\n",
    "        \n",
    "        output_dir = section_dir + 'question_recognition/'\n",
    "        try:\n",
    "            os.makedirs(output_dir)\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "        print('Starting ' + image_dir)\n",
    "        # sample document\n",
    "        \n",
    "        with open(input_dir, 'rb') as f:\n",
    "        \n",
    "            poller = document_intelligence_client.begin_analyze_document(model_id=\"prebuilt-document\", document=f)\n",
    "        \n",
    "        result = poller.result().to_dict()\n",
    "        \n",
    "        with open(output_dir+section_name+'.json', 'w') as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "        print('Finished ' + image_dir)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1.1', 0.995)\n",
      "('2.1', 0.995)\n",
      "('3.4', 0.995)\n",
      "('4.1', 0.995)\n",
      "[   {   'confidence': 0.995,\n",
      "        'path_index': '0',\n",
      "        'question_number': '1',\n",
      "        'section_index': '1'},\n",
      "    {   'confidence': 0.995,\n",
      "        'path_index': '1',\n",
      "        'question_number': '1',\n",
      "        'section_index': '2'},\n",
      "    {   'confidence': 0.995,\n",
      "        'path_index': '2',\n",
      "        'question_number': '4',\n",
      "        'section_index': '3'},\n",
      "    {   'confidence': 0.995,\n",
      "        'path_index': '3',\n",
      "        'question_number': '1',\n",
      "        'section_index': '4'}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "\n",
    "def stack_images_vertically(img1, img2):\n",
    "\n",
    "    # Get the dimensions of both images\n",
    "    width1, height1 = img1.size\n",
    "    width2, height2 = img2.size\n",
    "\n",
    "    # Calculate the dimensions for the new image\n",
    "    new_width = max(width1, width2)\n",
    "    new_height = height1 + height2\n",
    "\n",
    "    # Create a new blank image with the calculated dimensions\n",
    "    new_image = Image.new('RGB', (new_width, new_height))\n",
    "\n",
    "    # Paste the first image at the top\n",
    "    new_image.paste(img1, (0, 0))\n",
    "\n",
    "    # Paste the second image below the first image\n",
    "    new_image.paste(img2, (0, height1))\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "#match left and right single quotes\n",
    "single_quote_expr = re.compile(r'[\\u2018\\u2019]', re.U)\n",
    "#match all non-basic latin unicode\n",
    "unicode_chars_expr = re.compile(r'[\\u0080-\\uffff]', re.U)\n",
    "\n",
    "def cleanse_unicode(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    \n",
    "    temp = single_quote_expr.sub(\"'\", s, re.U)\n",
    "    temp = unicode_chars_expr.sub(\"\", temp, re.U)\n",
    "    return temp\n",
    "\n",
    "def filenameify(s):\n",
    "    s = cleanse_unicode(s)\n",
    "    replace_dict = {\n",
    "        \"①\": \"1\",\n",
    "        \"②\": \"2\",\n",
    "        \"③\": \"3\",\n",
    "        \"④\": \"4\",\n",
    "        \"⑤\": \"5\",\n",
    "        \"⑥\": \"6\",\n",
    "        \"⑦\": \"7\",\n",
    "        \"⑧\": \"8\",\n",
    "        \"⑨\": \"9\",\n",
    "        \"⑩\": \"10\",\n",
    "        \"⑪\": \"11\",\n",
    "        \"⑫\": \"12\",\n",
    "        \"⑬\": \"13\",\n",
    "        \"⑭\": \"14\",\n",
    "        \"⑮\": \"15\",\n",
    "        \"⑯\": \"16\",\n",
    "        \"⑰\": \"17\",\n",
    "        \"⑱\": \"18\",\n",
    "        \"⑲\": \"19\",\n",
    "        \"⑳\": \"20\",\n",
    "        \".\": \"\",\n",
    "        \"\\n\": \"\",\n",
    "        # \"/\": \"\"\n",
    "    }\n",
    "    \n",
    "    # https://www.geeksforgeeks.org/python-replace-words-from-dictionary/\n",
    "    replaced_s = \" \".join(replace_dict.get(ele, ele) for ele in s.split())\n",
    "    \n",
    "    filename = re.sub(r'[^a-zA-Z0-9._-]', '', replaced_s)\n",
    "    \n",
    "    if (len(filename) == 0):\n",
    "        return \"NOT_VALID_QUESTION_ID\"\n",
    "    \n",
    "    return filename\n",
    "for name in os.listdir(output_path):\n",
    "    \n",
    "    section_path = output_path+name+'/sections/'\n",
    "    \n",
    "    section_data = []\n",
    "    \n",
    "    for section in os.listdir(output_path+name+'/sections/'):\n",
    "        section_dir = section_path +section+'/'\n",
    "        section_name = name+'_s'+section\n",
    "        \n",
    "        with open(section_dir+'question_recognition/'+section_name+'.json', 'r') as f:\n",
    "            question_data = json.load(f)\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        for item in question_data[\"key_value_pairs\"]:\n",
    "            if (item[\"value\"]):\n",
    "                if (item[\"value\"][\"content\"] == \":selected:\"):\n",
    "                    data.append((filenameify(item[\"key\"][\"content\"]), item[\"confidence\"]))\n",
    "            \n",
    "        # highest confidence\n",
    "        data.sort(key=lambda a: a[1], reverse=True)\n",
    "        \n",
    "        if (len(data) > 0):\n",
    "            most_confident_item = data[0]\n",
    "            section_data.append({\n",
    "                \"section_index\": most_confident_item[0].split('.')[0],\n",
    "                \"question_number\": most_confident_item[0].split('.')[1],\n",
    "                \"path_index\": section,\n",
    "                \"confidence\": most_confident_item[1]\n",
    "            })\n",
    "    \n",
    "    \n",
    "    \n",
    "    question_number_dict = {}\n",
    "    \n",
    "    for section_info in section_data:\n",
    "        if (section_info[\"question_number\"] not in question_number_dict):\n",
    "            question_number_dict[section_info[\"question_number\"]] = []\n",
    "        \n",
    "        question_number_dict[section_info[\"question_number\"]].append(section_info)\n",
    "    \n",
    "    \n",
    "    question_output = output_path + name + '/questions/'\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(question_output)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    for question_id in question_number_dict.keys():\n",
    "        images = sorted(question_number_dict[question_id], key=lambda x: x[\"section_index\"])\n",
    "        if len(images) > 0:\n",
    "            \n",
    "            \n",
    "            stacked_image_path = section_path+images[0][\"path_index\"]+'/answer/'+name+'_s'+images[0][\"path_index\"]+'.png'\n",
    "            stacked_image = Image.open(stacked_image_path)\n",
    "            for section in images[1::]:\n",
    "                new_image_path = section_path+section[\"path_index\"]+'/answer/'+name+'_s'+section[\"path_index\"]+'.png'\n",
    "                new_image = Image.open(new_image_path)\n",
    "\n",
    "                \n",
    "                stacked_image = stack_images_vertically(stacked_image, new_image)\n",
    "            \n",
    "            question_id_path = question_output+question_id+'/'\n",
    "            try:\n",
    "                os.makedirs(question_id_path)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            stacked_image.save(question_id_path+name+'_q'+question_id+'.png')\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import tiktoken\n",
    "import json\n",
    "from PIL import Image\n",
    "import math\n",
    "from pydantic import BaseModel\n",
    "from io import BytesIO\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "current_path = os.getcwd() \n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    #   https://github.com/openai/tiktoken?tab=readme-ov-file#-tiktoken\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        \n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for data_value in message[\"content\"]:\n",
    "            if (data_value[\"type\"] == \"text\"):\n",
    "                data = data_value[\"text\"]\n",
    "            \n",
    "            if (data_value[\"type\"] == \"image_url\"):\n",
    "                data = data_value[\"image_url\"][\"url\"]    \n",
    "            if (data):\n",
    "                num_tokens += len(encoding.encode(data))\n",
    "            # if data_value[\"type\"] == \"name\":  # if there's a name, the role is omitted\n",
    "            #     num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "    return num_tokens\n",
    "\n",
    "# https://platform.openai.com/docs/guides/vision \n",
    "def encode_image(image_path):\n",
    "    pillow_image = Image.open(image_path)\n",
    "    \n",
    "    percent = 1\n",
    "\n",
    "    new_width = int(pillow_image.width * percent)\n",
    "    new_height = int(float(pillow_image.size[1]) * percent)\n",
    "    \n",
    "    resized_image = pillow_image.resize((new_width, new_height))\n",
    "    buffered = BytesIO()\n",
    "    resized_image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "def copy_image(image_path, target_path):\n",
    "    shutil.copy(image_path, target_path)\n",
    "\n",
    "\n",
    "# schema classes\n",
    "class SpellingCorrection(BaseModel):\n",
    "    original: str\n",
    "    changes: str\n",
    "\n",
    "# answer class schema\n",
    "class QuestionAnswer(BaseModel):\n",
    "    # let openai reasses the question number (they are better than google )\n",
    "    certainty: float \n",
    "    student_handwriting_percent: float\n",
    "    # get the unchanged raw tekst\n",
    "    raw_text: str\n",
    "    # get the spel corrected tekst that should be graded\n",
    "    correctly_spelled_text: str\n",
    "    # get the spelling changes the model made\n",
    "    spelling_corrections: list[SpellingCorrection]\n",
    "\n",
    "def get_client():\n",
    "    with open(\"creds/openaikey.json\", \"r\") as f:\n",
    "        openai_key = json.load(f)[\"key\"]\n",
    "    \n",
    "\n",
    "    openai_client = OpenAI(api_key=openai_key)\n",
    "    \n",
    "    return openai_client\n",
    "\n",
    "def get_response_json(response, gpt_model, start_time, end_time):\n",
    "    \n",
    "    dict_response = response.to_dict()\n",
    "    choice_response = dict_response[\"choices\"][0]\n",
    "    result_data = choice_response[\"message\"][\"parsed\"]\n",
    "    request_data = dict_response[\"usage\"]\n",
    "\n",
    "    output_json = {\n",
    "\n",
    "        \"question_number\": result_data[\"question_number\"],\n",
    "        \"raw_text\": result_data[\"raw_text\"],\n",
    "        \"correctly_spelled_text\": result_data[\"correctly_spelled_text\"],\n",
    "        \"spelling_corrections\": result_data[\"spelling_corrections\"],\n",
    "        \n",
    "        \"tokens_used\": request_data[\"total_tokens\"],\n",
    "\n",
    "        \"model_used\": gpt_model,\n",
    "        \"model_version\": dict_response[\"model\"],\n",
    "        \n",
    "        \"timestamp\": int(end_time),\n",
    "        \"delta_time_s\": end_time - start_time,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return output_json\n",
    "\n",
    "\n",
    "def single_request(messages, name, question):\n",
    "    \n",
    "    openai_client = get_client()\n",
    "    \n",
    "    gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"GPT request... \")\n",
    "    \n",
    "    try:\n",
    "        response = openai_client.beta.chat.completions.parse(\n",
    "            model=gpt_model,\n",
    "            temperature=0.05,\n",
    "            messages=messages,\n",
    "            response_format=QuestionAnswer,\n",
    "            # max_tokens=30_000, #test image was 15k tokens\n",
    "            timeout=14\n",
    "        )\n",
    "    except:\n",
    "        print(\"GPT request... ERROR\")\n",
    "        return False\n",
    "    print(\"GPT request... Done\")\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # from pprint import pprint\n",
    "    # pprint(response)\n",
    "    json_output_path = f\"./output/{name}/questions/{question}/json/\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        os.makedirs(json_output_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # copy image here\n",
    "    # copy_image(input_image_path, image_json_output_path)\n",
    "        \n",
    "\n",
    "    json_output_path = json_output_path + \"/\" + gpt_model + \".json\"\n",
    "\n",
    "    reponse_json = get_response_json(response, gpt_model, start_time, end_time)\n",
    "    reponse_json[\"question_id\"] = question\n",
    "    json_string = json.dumps(reponse_json, indent=4)\n",
    "\n",
    "    with open(json_output_path, \"w\") as outfile:\n",
    "        outfile.write(json_string)\n",
    "        \n",
    "    print(\"Written to file \"+json_output_path)\n",
    "\n",
    "def batch_request(api_requests):\n",
    "    openai_client = get_client()\n",
    "    \n",
    "    gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "    request_id = uuid.uuid4()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"GPT request... \")\n",
    "    request_data = []\n",
    "    \n",
    "    for (i, api_request) in enumerate(api_requests):\n",
    "        request_data.append({\n",
    "            \"custom_id\": \"request-\"+i, \n",
    "            \"method\": \"POST\", \n",
    "            \"url\": \"/v1/chat/completions\", \n",
    "            \"body\": api_request\n",
    "        })\n",
    "    \n",
    "    \n",
    "    with open(\"batchinput.jsonl\", \"w\") as f:\n",
    "        f.write(request_data)\n",
    "    \n",
    "    input_file = openai_client.files.create(\n",
    "        file=open(\"batchinput.jsonl\", \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        batch_input_file_id = input_file.id\n",
    "\n",
    "        batch_data = openai_client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"h\",\n",
    "            metadata={\n",
    "                \"description\": \"nightly eval job\"\n",
    "            }\n",
    "        )\n",
    "    except:\n",
    "        print(\"GPT request... ERROR\")\n",
    "        return False\n",
    "    \n",
    "    with open('./batch/'+request_id+'.json', 'w') as f:\n",
    "        f.write(batch_data)\n",
    "    \n",
    "    print(\"GPT request... Done\")\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # # from pprint import pprint\n",
    "    # # pprint(response)\n",
    "    # json_output_path = current_path + r\"/single_request_json_output\"\n",
    "\n",
    "\n",
    "    # try:\n",
    "    #     os.makedirs(json_output_path)\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    # student_json_output_path = json_output_path + \"/\"\n",
    "    # # + student + \"/sections\" \n",
    "    # try:\n",
    "    #     os.makedirs(student_json_output_path)\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    # # TODO: choose better name\n",
    "    # #  currently using the original image file name\n",
    "    # image_json_output_path = student_json_output_path #+ \"/\" + image_name\n",
    "    # try:\n",
    "    #     os.makedirs(image_json_output_path)\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    # # copy image here\n",
    "    # # copy_image(input_image_path, image_json_output_path)\n",
    "        \n",
    "\n",
    "    # json_output_path = image_json_output_path + \"/\" + gpt_model + \"_result.json\"\n",
    "\n",
    "    # reponse_json = get_response_json(response, gpt_model, start_time, end_time)\n",
    "\n",
    "    # with open(json_output_path, \"w\") as outfile:\n",
    "    #     outfile.write(reponse_json)\n",
    "        \n",
    "    # print(\"Written to file \"+json_output_path)\n",
    "\n",
    "def scan_section_data(image_path):\n",
    "\n",
    "\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"Je krijgt een foto van een Nederlandse toetsantwoord. \n",
    "                                Je moet deze omzetten in tekst. \n",
    "                                Deze toets moet nog worden nagekeken je. \n",
    "                                Verander niets aan de inhoud. \n",
    "                                Bedenk geen nieuwe woorden of woordonderdelen. \n",
    "                                Verander alleen kleine spelfoutjes.\n",
    "                                houd in het antwoord ook rekening met meerdere regels en geeft die aan met een '\\\\n'\n",
    "                                \"\"\"\n",
    "                                # de vraagnummers moeten getallen zijn\n",
    "                                # als een vraagnummer een letter heeft, bijvoorbeeld 1a of 2c\n",
    "                                # noteer dat dan al volgt: 1.a en 2.c dus, {getal}.{letter}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Geef antwoord in JSON zoals in een aangegeven schema staat\"    \n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"extraheer de tekst\"    \n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "\n",
    "\n",
    "    num_tokens = num_tokens_from_messages(messages= messages,model=\"gpt-4o\")\n",
    "\n",
    "    # if (input(f\"execute {num_tokens}? (y/n)\") != \"y\" ):\n",
    "        # exit()\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "\n",
    "# scan_section(student, image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 - input - 1 ...\n",
      "GPT request... \n",
      "GPT request... Done\n",
      "Written to file ./output/input/questions/1/json//gpt-4o-mini.json\n",
      "Starting 1 - input - 1 ... Done\n",
      "Starting 2 - input - 1n ...\n",
      "GPT request... \n",
      "GPT request... Done\n",
      "Written to file ./output/input/questions/1n/json//gpt-4o-mini.json\n",
      "Starting 2 - input - 1n ... Done\n",
      "Starting 3 - input - 4 ...\n",
      "GPT request... \n",
      "GPT request... Done\n",
      "Written to file ./output/input/questions/4/json//gpt-4o-mini.json\n",
      "Starting 3 - input - 4 ... Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import psutil\n",
    "\n",
    "def ask_image(path) -> bool:\n",
    "    img = Image.open(path)\n",
    "    img.show()\n",
    "    result = input(\"Send to gpt (y/n) 'quit' = quit: \")\n",
    "    return result\n",
    "    \n",
    "image_paths_to_process = []\n",
    "    \n",
    "i = 0    \n",
    "if os.path.exists(\"output/\"):\n",
    "    \n",
    "    for name in os.listdir(\"output/\"):\n",
    "\n",
    "\n",
    "        for question in os.listdir(f\"output/{name}/questions/\"):\n",
    "            \n",
    "            # scan = ask_image(f\"section_output/{student}/sections/{section}\")\n",
    "            # control over usage of api\n",
    "            # if scan == \"y\":\n",
    "            clean_section_name = question.replace('.png', '' )\n",
    "            \n",
    "            i+=1\n",
    "            print(f\"Starting {i} - {name} - {question} ...\")   \n",
    "            path = f\"./output/{name}/questions/{question}/{name}_q{question}.png\"\n",
    "            \n",
    "            data = scan_section_data(path)\n",
    "            single_request(data, name, question)\n",
    "            image_paths_to_process.append(path)\n",
    "            print(f\"Starting {i} - {name} - {question} ... Done\")   \n",
    "\n",
    "            # if (scan == \"quit\"):\n",
    "                # raise SystemExit(0)\n",
    "\n",
    "scan_section_data = [scan_section_data(path) for path in image_paths_to_process]\n",
    "\n",
    "\n",
    "# with open('./batch_requests/'+uuid.uuidv4()) as f:\n",
    "\n",
    "# batch_request()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
