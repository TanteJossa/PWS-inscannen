{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import math\n",
    "import time\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "import os\n",
    "\n",
    "research_dir = \"./research/\"\n",
    "\n",
    "try: \n",
    "    os.makedirs(research_dir)\n",
    "except: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GEMINI\n",
    "\n",
    "def compare_strings(str1, str2):\n",
    "    \"\"\"Compares two strings and returns a list of tuples indicating changes.\n",
    "\n",
    "    Args:\n",
    "        str1: The original string.\n",
    "        str2: The modified string.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, each containing a range of indices and the replacement text.\n",
    "    \"\"\"\n",
    "\n",
    "    matcher = difflib.SequenceMatcher(None, str1, str2)\n",
    "    diffs = matcher.get_opcodes()\n",
    "\n",
    "    changes = []\n",
    "    for tag, i1, i2, j1, j2 in diffs:\n",
    "        if tag == 'delete':\n",
    "            changes.append((tag, (i1, i2), \"\"))\n",
    "        elif tag == 'insert':\n",
    "            changes.append((tag, (i1, i1), str2[j1:j2]))\n",
    "        elif tag == 'replace':\n",
    "            changes.append((tag, (i1, i2), str2[j1:j2]))\n",
    "\n",
    "    return changes\n",
    "\n",
    "def score_dutch_text(reference_text, generated_text,language = 'dutch'):\n",
    "    # print(reference_text, '\\n', generated_text)\n",
    "    \"\"\"\n",
    "    Scores the quality of a Dutch generated text compared to a reference text.\n",
    "\n",
    "    Args:\n",
    "        reference_text (str): The reference Dutch text.\n",
    "        generated_text (str): The generated Dutch text.\n",
    "\n",
    "    Returns:\n",
    "        float: A score between 0 and 1, with 1 being a perfect match.\n",
    "    \"\"\"\n",
    "\n",
    "    reference_tokens = word_tokenize(reference_text, language=language)\n",
    "    generated_tokens = word_tokenize(generated_text, language=language)\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    bleu_score = sentence_bleu([reference_tokens], generated_tokens)\n",
    "    # Calculate word-level accuracy\n",
    "    correct_words = 0\n",
    "    # for ref_word, gen_word in zip(reference_tokens, generated_tokens):\n",
    "    #     if ref_word == gen_word:\n",
    "    #         correct_words += 1\n",
    "    word_accuracy = correct_words / len(reference_tokens)\n",
    "\n",
    "    # Calculate edit distance using Difflib\n",
    "    matcher = difflib.SequenceMatcher(None, reference_text, generated_text)\n",
    "    ops = matcher.get_opcodes()\n",
    "    edit_distance_penalty = 0\n",
    "    for tag, i1, i2, j1, j2 in ops:\n",
    "        if tag == 'delete' or tag == 'insert' or tag == 'replace':\n",
    "            edit_distance_penalty += (i2 - i1) + (j2 - j1)\n",
    "            \n",
    "    average_text_length = (len(reference_text) +  len(generated_text)) / 2\n",
    "\n",
    "    # Calculate the final score\n",
    "    final_score = (abs(bleu_score - 1) * 0.5) + (word_accuracy * 0.3) + (edit_distance_penalty / len(reference_text))\n",
    "\n",
    "    return float(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN AI gpt 4o\n",
    "cruijff_score_inputs = [\n",
    "\n",
    "    {\n",
    "        \"quote\": \"Je moet schieten, anders kun je niet scoren.\",\n",
    "        \"quote_changed\": \"Je moet schieten, nders kun je niet scoren.\",\n",
    "        \"person\": \"Johan Cruijff\",\n",
    "        \"year\": 1980,\n",
    "        \"test\": \"enkele letterverandering\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Je moet schieten, anders kun je niet scoren.\",\n",
    "        \"quote_changed\": \"Je moet schoten, anders kun je niet scoren.\",\n",
    "        \"person\": \"Johan Cruijff\",\n",
    "        \"year\": 1980,\n",
    "        \"test\": \"enkele woordverandering, geen betekenisverandering\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Je moet schieten, anders kun je niet scoren.\",\n",
    "        \"quote_changed\": \"Je moet roeien, anders kun je niet scoren.\",\n",
    "        \"person\": \"Johan Cruijff\",\n",
    "        \"year\": 1980,\n",
    "        \"test\": \"enkele woordverandering, wel betekenisverandering\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Je moet schieten, anders kun je niet scoren.\",\n",
    "        \"quote_changed\": \"Je moet schoten, anders kun je niet scoren.\",\n",
    "        \"person\": \"Johan Cruijff\",\n",
    "        \"year\": 1980,\n",
    "        \"test\": \"woordweglating\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Je moet schieten, anders kun je niet scoren.\",\n",
    "        \"quote_changed\": \"Je moet schoten,.\",\n",
    "        \"person\": \"Johan Cruijff\",\n",
    "        \"year\": 1980,\n",
    "        \"test\": \"zinsdeelweglating\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Je moet schieten, anders kun je niet scoren.\",\n",
    "        \"quote_changed\": \"\",\n",
    "        \"person\": \"Johan Cruijff\",\n",
    "        \"year\": 1980,\n",
    "        \"test\": \"tekstweglating\",\n",
    "    },\n",
    "]\n",
    "different_score_input = [\n",
    "    {\n",
    "        \"quote\": \"Ik heb een heel zwaar leven.\",\n",
    "        \"quote_changed\": \"Ik heb een heel zwaar leven.\",\n",
    "        \"person\": \"Brigitte Kaandorp\",\n",
    "        \"year\": 2009,\n",
    "        \"test\": \"nulmeting\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Ik geloof in God, behalve als ik vis.\",\n",
    "        \"quote_changed\": \"Ik geloof in God, be\",\n",
    "        \"person\": \"Herman Brood\",\n",
    "        \"year\": 1995,\n",
    "        \"test\": \"weglating aan einde\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Als het niet kan zoals het moet, dan moet het maar zoals het kan.\",\n",
    "        \"quote_changed\": \"Als het niet kan zoals  het maar zoals het kan.\",\n",
    "        \"person\": \"Dolf Jansen\",\n",
    "        \"year\": 2005,\n",
    "        \"test\": \" weglating in midden\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Ik heb nooit last van hoogtevrees, wel van dieptevrees.\",\n",
    "        \"quote_changed\": \"Ik hebt ooit last van hoogtevrees, well vann dieptevrees.\",\n",
    "        \"person\": \"Youp van 't Hek\",\n",
    "        \"year\": 1998,\n",
    "        \"test\": \"enkele letterweglating, betekenisverandering\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Ik ben niet dik, ik ben een ruimtewonder.\",\n",
    "        \"quote_changed\": \"Ik bn nit dik, ik bn n ruimtwondr.\",\n",
    "        \"person\": \"Brigitte Kaandorp\",\n",
    "        \"year\": 2003,\n",
    "        \"test\": \"letter e weggelaten\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Een dag niet gelachen is een dag niet geleefd.\",\n",
    "        \"quote_changed\": \"Een dag niet gelachen is een dag niet geleeft.\",\n",
    "        \"person\": \"Charlie Chaplin\",\n",
    "        \"year\": 1930,\n",
    "        \"test\": \"enkele letterverandering , geen betekenisverandering\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Een dag niet gelachen is een dag niet geleefd.\",\n",
    "        \"quote_changed\": \"Een  niet gelachen is een dag niet geleefd.\",\n",
    "        \"person\": \"Charlie Chaplin\",\n",
    "        \"year\": 1930,\n",
    "        \"test\": \"woordweglating\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Ik ben niet gek, ik ben een vliegtuig.\",\n",
    "        \"quote_changed\": \"Ik ben niet , ik  een .\",\n",
    "        \"person\": \"Supergrover\",\n",
    "        \"year\": 1974,\n",
    "        \"test\": \"dubbelle woordweglating\",\n",
    "    },\n",
    "    { \n",
    "        \"quote\": \"Ik begrijp niet waarom u hier zo negatief en vervelend over doet. (...) Laten we blij zijn met elkaar! Laten wij optimistisch zijn! Laten we zeggen: Nederland kan het weer! Die VOC-mentaliteit, over grenzen heen kijken, dynamiek! Toch?\",\n",
    "        \"quote_changed\": \"Ik begrijp niet waarom u hier zo negatief en vervelend over doet. (...) Laten we blij zijn met elkaar! Laten wij optimistisch zijn! Laten we zeggen: Nederland kan het weer! Die\",\n",
    "        \"person\": \"Jan-Peter Balkenende\",\n",
    "        \"year\": 2006,\n",
    "        \"test\": \"weglating einde van grotere tekst\",\n",
    "    },\n",
    "    { \n",
    "        \"quote\": \"Praat Nederlands met me. Even Nederlands met me. Mijn gevoel zegt mij dat wij vanavond samen kijken. Naar de Champs-Élysées en naar de Notre Dame en naar de Seine. En daarna samen op La Tour Eiffel\",\n",
    "        \"quote_changed\": \"Praat Nedertands met me. Even Neterlands met me. Mijn tevoet zegt mij dat wij vanatond samet kitken. Naar de Champs-Éltsées en naar de Notre Dameten naar detSeine. En daarta samet op La Tour Etffel\",\n",
    "        \"person\": \"Kenny B\",\n",
    "        \"year\": 2015,\n",
    "        \"test\": \"random lettermutaties\",\n",
    "    },\n",
    "    {\n",
    "        \"quote\": \"Rrrrrr, hah, is gewoon Boef man. Ha, jij bent vies maar ik doe gemener. In de club, kom je moeder tegen. En ik wil snel weg want we moeten wegen. En je klant is geholpen, je moet vroeger wezen. Ik was alles kwijt, maar floes herenigd. Voor me zondes af en toe gebeden. Ik ga uit eten voor een goede prijs. Ik ben een uitgever, ze boeken mij. Van alarm voorzien aan de achterkant. Dus ze komen via voor, maar wat dacht je dan?\",\n",
    "        \"quote_changed\": \"Rrrrrr, hah, is gewoon Boef man.test, jij bent vies maar ik doe gemener. In de club, komtest moeder tegen. En ik wil snel weg wantest we moeten wegen. En je klant is geholpen, je moetest vroeger wezen. Ik was alles kwijt, maar floetest herenigd. Voor me zondes af en toe gebeden. Ik gtest uit eten voor een goede prijs. Ik ben een uitgever, ze boeken mij. Van alarm voortest aan de achterkant. Dus ze komen via voor, maar wat dacht je dan?\",\n",
    "        \"person\": \"Boef\",\n",
    "        \"year\": 2017,\n",
    "        \"test\": \"random toevoeging woorden\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'quote': 'Je moet schieten, anders kun je niet scoren.', 'quote_changed': 'Je moet schieten, nders kun je niet scoren.', 'person': 'Johan Cruijff', 'year': 1980, 'test': 'enkele letterverandering', 'score': 0.19370876948914964, 'changes': [('delete', (18, 19), '')]}, {'quote': 'Je moet schieten, anders kun je niet scoren.', 'quote_changed': 'Je moet schoten, anders kun je niet scoren.', 'person': 'Johan Cruijff', 'year': 1980, 'test': 'enkele woordverandering, geen betekenisverandering', 'score': 0.21462842758854445, 'changes': [('replace', (11, 13), 'o')]}, {'quote': 'Je moet schieten, anders kun je niet scoren.', 'quote_changed': 'Je moet roeien, anders kun je niet scoren.', 'person': 'Johan Cruijff', 'year': 1980, 'test': 'enkele woordverandering, wel betekenisverandering', 'score': 0.3282647912249081, 'changes': [('replace', (8, 11), 'roe'), ('delete', (12, 14), '')]}, {'quote': 'Je moet schieten, anders kun je niet scoren.', 'quote_changed': 'Je moet schoten, anders kun je niet scoren.', 'person': 'Johan Cruijff', 'year': 1980, 'test': 'woordweglating', 'score': 0.21462842758854445, 'changes': [('replace', (11, 13), 'o')]}, {'quote': 'Je moet schieten, anders kun je niet scoren.', 'quote_changed': 'Je moet schoten,.', 'person': 'Johan Cruijff', 'year': 1980, 'test': 'zinsdeelweglating', 'score': 1.1590909090909092, 'changes': [('replace', (11, 13), 'o'), ('delete', (17, 43), '')]}, {'quote': 'Je moet schieten, anders kun je niet scoren.', 'quote_changed': '', 'person': 'Johan Cruijff', 'year': 1980, 'test': 'tekstweglating', 'score': 1.5, 'changes': [('delete', (0, 44), '')]}]\n",
      "[{'quote': 'Ik heb een heel zwaar leven.', 'quote_changed': 'Ik heb een heel zwaar leven.', 'person': 'Brigitte Kaandorp', 'year': 2009, 'test': 'nulmeting', 'score': 0.0, 'changes': []}, {'quote': 'Ik geloof in God, behalve als ik vis.', 'quote_changed': 'Ik geloof in God, be', 'person': 'Herman Brood', 'year': 1995, 'test': 'weglating aan einde', 'score': 0.7644031351267621, 'changes': [('delete', (20, 37), '')]}, {'quote': 'Als het niet kan zoals het moet, dan moet het maar zoals het kan.', 'quote_changed': 'Als het niet kan zoals  het maar zoals het kan.', 'person': 'Dolf Jansen', 'year': 2005, 'test': ' weglating in midden', 'score': 0.49014852696378863, 'changes': [('delete', (23, 41), '')]}, {'quote': 'Ik heb nooit last van hoogtevrees, wel van dieptevrees.', 'quote_changed': 'Ik hebt ooit last van hoogtevrees, well vann dieptevrees.', 'person': \"Youp van 't Hek\", 'year': 1998, 'test': 'enkele letterweglating, betekenisverandering', 'score': 0.4277380519915124, 'changes': [('insert', (6, 6), 't'), ('delete', (7, 8), ''), ('insert', (38, 38), 'l'), ('insert', (41, 41), 'n')]}, {'quote': 'Ik ben niet dik, ik ben een ruimtewonder.', 'quote_changed': 'Ik bn nit dik, ik bn n ruimtwondr.', 'person': 'Brigitte Kaandorp', 'year': 2003, 'test': 'letter e weggelaten', 'score': 0.6707317073170732, 'changes': [('delete', (4, 5), ''), ('delete', (9, 10), ''), ('delete', (21, 22), ''), ('delete', (24, 26), ''), ('delete', (33, 34), ''), ('delete', (38, 39), '')]}, {'quote': 'Een dag niet gelachen is een dag niet geleefd.', 'quote_changed': 'Een dag niet gelachen is een dag niet geleeft.', 'person': 'Charlie Chaplin', 'year': 1930, 'test': 'enkele letterverandering , geen betekenisverandering', 'score': 0.15220711585124339, 'changes': [('replace', (44, 45), 't')]}, {'quote': 'Een dag niet gelachen is een dag niet geleefd.', 'quote_changed': 'Een  niet gelachen is een dag niet geleefd.', 'person': 'Charlie Chaplin', 'year': 1930, 'test': 'woordweglating', 'score': 0.16739880820827535, 'changes': [('delete', (4, 7), '')]}, {'quote': 'Ik ben niet gek, ik ben een vliegtuig.', 'quote_changed': 'Ik ben niet , ik  een .', 'person': 'Supergrover', 'year': 1974, 'test': 'dubbelle woordweglating', 'score': 0.8947368421052632, 'changes': [('delete', (12, 15), ''), ('delete', (20, 23), ''), ('delete', (28, 37), '')]}, {'quote': 'Ik begrijp niet waarom u hier zo negatief en vervelend over doet. (...) Laten we blij zijn met elkaar! Laten wij optimistisch zijn! Laten we zeggen: Nederland kan het weer! Die VOC-mentaliteit, over grenzen heen kijken, dynamiek! Toch?', 'quote_changed': 'Ik begrijp niet waarom u hier zo negatief en vervelend over doet. (...) Laten we blij zijn met elkaar! Laten wij optimistisch zijn! Laten we zeggen: Nederland kan het weer! Die', 'person': 'Jan-Peter Balkenende', 'year': 2006, 'test': 'weglating einde van grotere tekst', 'score': 0.3767350827049003, 'changes': [('delete', (176, 235), '')]}, {'quote': 'Praat Nederlands met me. Even Nederlands met me. Mijn gevoel zegt mij dat wij vanavond samen kijken. Naar de Champs-Élysées en naar de Notre Dame en naar de Seine. En daarna samen op La Tour Eiffel', 'quote_changed': 'Praat Nedertands met me. Even Neterlands met me. Mijn tevoet zegt mij dat wij vanatond samet kitken. Naar de Champs-Éltsées en naar de Notre Dameten naar detSeine. En daarta samet op La Tour Etffel', 'person': 'Kenny B', 'year': 2015, 'test': 'random lettermutaties', 'score': 0.48204781125878554, 'changes': [('replace', (11, 12), 't'), ('replace', (32, 33), 't'), ('replace', (54, 55), 't'), ('replace', (59, 60), 't'), ('replace', (82, 83), 't'), ('replace', (91, 92), 't'), ('replace', (95, 96), 't'), ('replace', (118, 119), 't'), ('replace', (145, 146), 't'), ('replace', (156, 157), 't'), ('replace', (171, 172), 't'), ('replace', (178, 179), 't'), ('replace', (192, 193), 't')]}, {'quote': 'Rrrrrr, hah, is gewoon Boef man. Ha, jij bent vies maar ik doe gemener. In de club, kom je moeder tegen. En ik wil snel weg want we moeten wegen. En je klant is geholpen, je moet vroeger wezen. Ik was alles kwijt, maar floes herenigd. Voor me zondes af en toe gebeden. Ik ga uit eten voor een goede prijs. Ik ben een uitgever, ze boeken mij. Van alarm voorzien aan de achterkant. Dus ze komen via voor, maar wat dacht je dan?', 'quote_changed': 'Rrrrrr, hah, is gewoon Boef man.test, jij bent vies maar ik doe gemener. In de club, komtest moeder tegen. En ik wil snel weg wantest we moeten wegen. En je klant is geholpen, je moetest vroeger wezen. Ik was alles kwijt, maar floetest herenigd. Voor me zondes af en toe gebeden. Ik gtest uit eten voor een goede prijs. Ik ben een uitgever, ze boeken mij. Van alarm voortest aan de achterkant. Dus ze komen via voor, maar wat dacht je dan?', 'person': 'Boef', 'year': 2017, 'test': 'random toevoeging woorden', 'score': 0.19282032005454008, 'changes': [('replace', (32, 35), 'test'), ('replace', (87, 90), 'test'), ('insert', (128, 128), 'est'), ('insert', (178, 178), 'est'), ('replace', (223, 224), 'test'), ('replace', (273, 274), 'test'), ('replace', (356, 360), 'test')]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\PWS-inscannen\\section_scanner\\app\\venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "d:\\GitHub\\PWS-inscannen\\section_scanner\\app\\venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "for items, name in [(cruijff_score_inputs, 'cruijff'), (different_score_input, 'different')]:\n",
    "    score_result_test_results = []\n",
    "    for test in items:\n",
    "        test[\"score\"] = score_dutch_text(test[\"quote\"], test[\"quote_changed\"])\n",
    "        test[\"changes\"] = compare_strings(test[\"quote\"], test[\"quote_changed\"])\n",
    "        \n",
    "        score_result_test_results.append(test)\n",
    "   \n",
    "    path =  research_dir+name+'_score_test.json'\n",
    "    # try: \n",
    "    #     os.makedirs(path)\n",
    "    # except: \n",
    "    #     pass\n",
    "    print(score_result_test_results)\n",
    "    score_result_test_results.sort(key=lambda x: x[\"score\"])\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(score_result_test_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [\n",
    "    {\n",
    "        \"image_name\": \"kort_leesbaar\",\n",
    "        \"expected_output\": \"\"\"Dit is een antwoord op vraag 2 en er is sprake van\n",
    "onvolledige verbranding.\"\"\",\n",
    "        \"reason\": \"gescanned simpele tekst leesbaar handschrift\",\n",
    "    },\n",
    "    {\n",
    "        \"image_name\": \"kort_onleesbaar\",\n",
    "        \"expected_output\": \"\"\"Dit is een antwoord op vraag 2 en er is sprake van onvolledige verbranding.\"\"\",\n",
    "        \"reason\": \"gescanned simpele tekst slecht handschrift\",\n",
    "    },\n",
    "    {\n",
    "        \"image_name\": \"kort_leesbaar_uitgekrast\",\n",
    "        \"expected_output\": \"\"\"Dit is een antwoord op vraag 2 en er is sprake van onvolledige verbranding.\"\"\",\n",
    "        \"reason\": \"gescanned simpele tekst leesbaar uitgekrast\",\n",
    "    },\n",
    "    {\n",
    "        \"image_name\": \"slecht_leesbaar_pijlen\",\n",
    "        \"expected_output\": \"\"\"Dit is een langer antwoord op vraag 6 het waxine lichtje brandt langer omdat \n",
    "er meer brandstof (kaarsevet) is en hij dus langer warmte, brandstof en zuurstof heeft.\"\"\",\n",
    "        \"reason\": \"gescanned tekst slecht leesbaar met uitgekrast en pijlen\",\n",
    "    },\n",
    "    {\n",
    "        \"image_name\": \"gekreukeld_met_pijlen\",\n",
    "        \"expected_output\": \"\"\"Dit is een langer antwoord op vraag 6 het waxine lichtje brandt langer omdat \n",
    "er meer brandstof (kaarsevet) is en hij dus langer warmte, brandstof en zuurstof heeft.\"\"\",\n",
    "        \"reason\": \"slechte foto slecht leesbaar met uitgekrast en pijlen\",\n",
    "    },\n",
    "    {\n",
    "        \"image_name\": \"gekreukeld_netjes\",\n",
    "        \"expected_output\": \"\"\"Dit is een antwoord op vraag 2 en er is sprake van onvolledige verbranding.\"\"\",\n",
    "        \"reason\": \"slechte foto goed leesbaar\",\n",
    "    },\n",
    "]\n",
    "\n",
    "models = [\n",
    "    # {\n",
    "    #     \"provider\": \"openai\",\n",
    "    #     \"model_name\": \"gpt-3.5-turbo\",\n",
    "    #     \"released\": \"sept 2021\",\n",
    "    #     \"reason\": \"een oud openai model\"\n",
    "    # },\n",
    "    {\n",
    "        \"provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4o-mini\",\n",
    "        \"released\": \"july 2024\",\n",
    "        \"reason\": \"deze is aangeraden door openai\"\n",
    "    },\n",
    "    {\n",
    "        \"provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-4o\",\n",
    "        \"released\": \"sept 2024\",\n",
    "        \"reason\": \"openai model met meer reasoning\"\n",
    "    },\n",
    "    {\n",
    "        \"provider\": \"google\",\n",
    "        \"model_name\": \"gemini-1.5-flash-8b\",\n",
    "        \"released\": \"sept 2024\",\n",
    "        \"reason\": \"Een snel model dat simpele taken uitvoert. \"\n",
    "    },\n",
    "    {\n",
    "        \"provider\": \"google\",\n",
    "        \"model_name\": \"gemini-1.5-pro-002\",\n",
    "        \"released\": \"sept 2024\",\n",
    "        \"reason\": \"Aanbevolen Google-model voor denkopgaven\"\n",
    "    },\n",
    "    # {\n",
    "    #     \"provider\": \"google\",\n",
    "    #     \"model_name\": \"gemini-1.0-pro-vision-001\",\n",
    "    #     \"released\": \"july 2024\",\n",
    "    #     \"reason\": \"ouder model gespecificeerd in foto herkenning\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"provider\": \"google\",\n",
    "    #     \"model_name\": \"gemini-exp-1121\",\n",
    "    #     \"released\": \"nov 2024\",\n",
    "    #     \"reason\": \"nieuwste google model die verbanden kan leggen\"\n",
    "    # },\n",
    "]\n",
    "\n",
    "temperatures = [\n",
    "    {\n",
    "        \"temperature\": 0,\n",
    "        \"repeat\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"temperature\": 0.5,\n",
    "        \"repeat\": 3,\n",
    "    },\n",
    "    {\n",
    "        \"temperature\": 1,\n",
    "        \"repeat\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"temperature\": 1.5,\n",
    "        \"repeat\": 6,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "transcribe_texts = [\n",
    "    {\n",
    "        \"text\": \"\"\"\n",
    "Zet de foto om naar tekst.\n",
    "        \"\"\",\n",
    "        \"reason\": \"de makkelijkste opdracht zonder extra uitleg\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"\n",
    "Je krijgt een foto van een Nederlands scheikunde toetsantwoord. \n",
    "Houdt rekening met pijlen.\n",
    "Je moet deze omzetten in text. Bedenk geen nieuwe woorden of woordonderdelen. \n",
    "geef waarschijnlijk fout gespelde woorden aan in de spelling corrections\n",
    "negeer uitgekrasde letters of woorden, geef die wil aan in spelling corrections\n",
    "de student_handwriting_percent is how leesbaar het handschrift van een leerling is: 0 betekend zeer moeilijk leesbaar en 100 netjes\n",
    "        \"\"\",\n",
    "        \"reason\": \"huidige opdracht met uitleg bij elk veld\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"\n",
    "Je krijgt een foto van een Nederlands scheikunde toets-antwoord. \n",
    "Je bent tekstherkenningssoftware die 10x beter in in tekst herkennen dan jezelf. Ook kan je 15.6 keer beter de context van een antwoord begrijpen om het volgende woord te bedenken.\n",
    "\n",
    "Het is helemaal niet toegestaan nieuwe woorden toe te voegen of de opgeschreven tekst te veranderen in het raw_text veld. Houdt wel rekening met pijlen in de volgorde van de tekst.\n",
    "Bedenk wel wat een leerling zou kunnen hebben bedoeld met een bepaald woord als die bijvoorbeeld fout is gespeld. Geef dat aan in de spelling_corrections velden.\n",
    "Negeer uitgekraste tekst in het raw_tekst veld, maar geef die wel weer in de spelling corrections door bijvoorbeeld streepjes neer te zetten en is_crossed_out op true te zetten.\n",
    "voeg alle text corrections samen in correctly_spelled_text om zo het antwoord te krijgen dat de leerling bedoelt.\n",
    "certainty is hoe zeker je bent dat je de tekst compleet hebt getranscribeerd: 0 betekend dat een docent er nog zelf naar moet kijken en 100 betekend dat er geen foutje mogelijk is.\n",
    "de student_handwriting_percent is hoe leesbaar het handschrift van een leerling is: 0 betekend zeer moeilijk leesbaar en 100 super netjes als een printer.\n",
    "\n",
    "voer deze opdracht zo goed mogelijk uit.\n",
    "\"\"\",\n",
    "        \"reason\": \"lange uitleg bij elk veld, zonder context\"\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "transcribe_text_additions = [\n",
    "    {\n",
    "    \n",
    "    },\n",
    "    {\n",
    "        \"stof\": \"stof\",\n",
    "    },\n",
    "    {\n",
    "        \"toets\": \"toets\",\n",
    "    },\n",
    "    # {\n",
    "    #     \"antwoordmodel\": \"antwoordmodel\",\n",
    "    # },\n",
    "    {\n",
    "        \"antwoordmodel bij vraag\": \"vraagspecifiek_antwoordmodel\",\n",
    "    },\n",
    "    # {\n",
    "    #     \"specifieke vraag vraag\": \"vraagspecifiek_vraag\",\n",
    "    # },\n",
    "    {\n",
    "        \"stof\": \"stof\",\n",
    "        \"toets\": \"toets\",\n",
    "        \"antwoordmodel\": \"antwoordmodel\",\n",
    "    },\n",
    "    {\n",
    "        \"stof\": \"stof\",\n",
    "        \"antwoordmodel bij vraag\": \"vraagspecifiek_antwoordmodel\",\n",
    "        \"specifieke vraag vraag\": \"vraagspecifiek_vraag\",\n",
    "    },\n",
    "    {\n",
    "        \"antwoordmodel bij vraag\": \"vraagspecifiek_antwoordmodel\",\n",
    "        \"specifieke vraag vraag\": \"vraagspecifiek_vraag\",\n",
    "    },\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scan_module import transcribe_answer\n",
    "from helpers import png_to_base64\n",
    "\n",
    "def scan_test_question(settings):\n",
    "    image_name = settings[\"image\"][\"image_name\"]\n",
    "    provider = settings[\"model\"][\"provider\"]\n",
    "    model = settings[\"model\"][\"model_name\"]\n",
    "    temperature = settings[\"temperature\"][\"temperature\"]\n",
    "    transcribe_text = settings[\"job\"][\"transcribe_text\"]\n",
    "    expected_output = settings[\"image\"][\"expected_output\"]\n",
    "    \n",
    "    base64_image = png_to_base64(research_dir+'/assets/sections/'+image_name+'.png')\n",
    "    \n",
    "    try:\n",
    "        result = transcribe_answer(\n",
    "            None, \n",
    "            base64_image=base64_image, \n",
    "            provider=provider,\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            request_text=transcribe_text,\n",
    "        )\n",
    "        # print(result)\n",
    "        # try:\n",
    "        raw_score = score_dutch_text(expected_output, result[\"result\"][\"raw_text\"])\n",
    "        raw_changes = compare_strings(expected_output, result[\"result\"][\"raw_text\"])\n",
    "        # except:\n",
    "        #     raw_score = 10\n",
    "        #     raw_changes = []\n",
    "        \n",
    "        try:\n",
    "            corrected_changes = compare_strings(expected_output, result[\"result\"][\"correctly_spelled_text\"])\n",
    "            corrected_score = score_dutch_text(expected_output, result[\"result\"][\"correctly_spelled_text\"])\n",
    "        except:\n",
    "            corrected_changes = raw_changes\n",
    "            corrected_score = raw_score\n",
    "\n",
    "        \n",
    "        return {\n",
    "            \"settings\": settings,\n",
    "            \"result\": result[\"result\"],\n",
    "            \"delta_time_s\": result[\"delta_time_s\"],\n",
    "            \"scores\": {\n",
    "                \"raw\": {\n",
    "                    \"score\": raw_score,\n",
    "                    \"changes\": raw_changes\n",
    "                },\n",
    "                \"corrected\": {\n",
    "                    \"score\": corrected_score,\n",
    "                    \"changes\": corrected_changes\n",
    "                }\n",
    "            },\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print('exception during transcribe: '+model, str(e))\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.test_context import test_context\n",
    "\n",
    "def split_array(arr, n):\n",
    "    return [arr[i:i + n] for i in range(0, len(arr), n)]\n",
    "\n",
    "# execute n at the same time\n",
    "n = 5\n",
    "# create execution settings\n",
    "to_execute = []\n",
    "\n",
    "for test_image in test_images:\n",
    "    for temperature in temperatures:\n",
    "        for transcribe_text in transcribe_texts:\n",
    "            for model in models:\n",
    "                for transcribe_text_addition in transcribe_text_additions:\n",
    "                    add_text = \"\"\n",
    "                    if len(transcribe_text_addition.keys()) > 0:\n",
    "                        add_text += \"\\n\\n Hier is context over de woorden die gebruikt kunnen worden: \\n\"\n",
    "                        for key in transcribe_text_addition.keys():\n",
    "                            add_text += \"context over \"+key+\":\\n\"+test_context[transcribe_text_addition[key]]+\"\\n\\n\" \n",
    "                    \n",
    "                    job = {\n",
    "                        \"base_command\": transcribe_text,\n",
    "                        \"addition\": transcribe_text_addition,\n",
    "                        \"transcribe_text\": transcribe_text[\"text\"] + add_text\n",
    "                    }\n",
    "                    \n",
    "                    settings = {\n",
    "                        \"image\": test_image,\n",
    "                        \"model\": model,\n",
    "                        \"temperature\": temperature,\n",
    "                        \"job\": job,\n",
    "                    }\n",
    "                    to_execute.append(settings)\n",
    "        \n",
    "split_executions = split_array(to_execute, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_execute' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dict_hash, get_random_id\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(split_executions[0][3][\"transcribe_text\"])\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# scan_test_question(split_executions[0][2])\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal to execute: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mto_execute\u001b[49m))\n\u001b[0;32m      9\u001b[0m min_file_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     10\u001b[0m repeats_per_setting \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'to_execute' is not defined"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from helpers import dict_hash, get_random_id\n",
    "\n",
    "# print(split_executions[0][3][\"transcribe_text\"])\n",
    "# scan_test_question(split_executions[0][2])\n",
    "\n",
    "print(\"Total to execute: \", len(to_execute))\n",
    "\n",
    "min_file_len = 50\n",
    "repeats_per_setting = 3\n",
    "current_results = []\n",
    "\n",
    "start_at = 475\n",
    "\n",
    "for i, split_execution in enumerate(split_executions[start_at::]):\n",
    "    execution_id = get_random_id()\n",
    "    \n",
    "    # continue\n",
    "    print('Starting: ', (i+1), '('+str((i+1)*n)+'/'+str(len(to_execute))+')')\n",
    "    \n",
    "    for i2 in range(repeats_per_setting):\n",
    "        # results = []\n",
    "        \n",
    "        # # use the hash of the settings as uuid\n",
    "        # for execution in split_execution:\n",
    "        #     result = scan_test_question(execution)\n",
    "        #     print(result)\n",
    "        #     results.append(result)\n",
    "                \n",
    "        # Use ThreadPoolExecutor to process sections concurrently\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            results = executor.map(scan_test_question, split_execution)\n",
    "\n",
    "\n",
    "        # Collect successfull results\n",
    "        results = [result for result in results if result]\n",
    "        \n",
    "\n",
    "        # use the hash of the settings as uuid\n",
    "        for result in results:\n",
    "            # hash = dict_hash(result[\"settings\"])\n",
    "            current_results.append(result)\n",
    "        \n",
    "    if (len(current_results) > min_file_len):\n",
    "        with open(research_dir+'transcribe_output/'+execution_id+'.json', 'w') as f:\n",
    "            json.dump(current_results, f, indent=4)\n",
    "        current_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when results are dicts\n",
    "\n",
    "import os\n",
    "\n",
    "compare_requests = []\n",
    "\n",
    "map_dir = 'transcribe_output_27_11_24'\n",
    "\n",
    "for name in os.listdir(research_dir+map_dir):\n",
    "    with open(research_dir+map_dir+'/'+name, 'r') as f:\n",
    "        data = json.load(f)\n",
    "                \n",
    "    compare_requests = compare_requests + list(data.values())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when results are lists\n",
    "\n",
    "import os\n",
    "\n",
    "compare_requests = []\n",
    "# kosten:\n",
    "# openai: 17 euro\n",
    "# google: 10 euro\n",
    "map_dir = 'transcribe_output_29_11_24'\n",
    "\n",
    "for name in os.listdir(research_dir+map_dir):\n",
    "    with open(research_dir+map_dir+'/'+name, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    if len(data) > len(compare_requests):\n",
    "        compare_requests = data\n",
    "    \n",
    "with open('all_data.json', 'w') as f:\n",
    "    json.dump(compare_requests, f, indent=4)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provider\n",
      "model\n",
      "temperature\n",
      "image\n",
      "base_command\n",
      "addition\n",
      "transcribe_text\n",
      "provider\n",
      "model\n",
      "temperature\n",
      "image\n",
      "base_command\n",
      "addition\n",
      "transcribe_text\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "items_per_result = 5\n",
    "\n",
    "def sort_results(results, text_type):\n",
    "    return sorted(results, key=lambda x: x[\"scores\"][text_type][\"score\"])\n",
    "\n",
    "def get_results_stats(results, text_type):\n",
    "    scores = list(map(lambda x: x[\"scores\"][text_type][\"score\"], results))\n",
    "    return {\n",
    "        \"average\": sum(scores) / len(scores),\n",
    "        \"standard_dev\": statistics.stdev(scores)\n",
    "    }\n",
    "    \n",
    "\n",
    "def get_dict_nestest_value(D, keys):\n",
    "    T = D\n",
    "    for i in keys:\n",
    "        T = T[i]\n",
    "    return T\n",
    "\n",
    "def group_by_key_and_sort(data, key, text_type):\n",
    "    grouped_data = defaultdict(list)\n",
    "    \n",
    "    for item in data:\n",
    "        \n",
    "        key_value = key(item[\"settings\"])\n",
    "        grouped_data[key_value].append(item)\n",
    "    \n",
    "    for item in grouped_data.keys():\n",
    "        \n",
    "        grouped_data[item] = sort_results(grouped_data[item], text_type)\n",
    "        \n",
    "    return dict(grouped_data)\n",
    "\n",
    "result = {}\n",
    "\n",
    "for text_type in [\"raw\", \"corrected\"]:\n",
    "\n",
    "\n",
    "    # all by score\n",
    "    by_score = sort_results(compare_requests, text_type)\n",
    "    by_score_stats = get_results_stats(by_score, text_type)\n",
    "    by_score_data = {\n",
    "        \"average\": by_score_stats[\"average\"],\n",
    "        \"standard_dev\": by_score_stats[\"standard_dev\"],\n",
    "        \"items\": by_score[0:items_per_result],\n",
    "    }\n",
    "    if \"all\" not in result:\n",
    "        result[\"all\"] = {}    \n",
    "        \n",
    "    result[\"all\"][text_type] = by_score_data\n",
    "\n",
    "    result_settings = {\n",
    "        \"provider\": lambda x: x['model']['provider'], \n",
    "        \"model\": lambda x: x['model']['model_name'],\n",
    "        \"temperature\": lambda x: x['temperature']['temperature'],\n",
    "        \"image\": lambda x: x[\"image\"]['image_name'], \n",
    "        \"base_command\": lambda x: x[\"job\"][\"base_command\"][\"text\"], \n",
    "        \"addition\": lambda x: \"-\".join(x[\"job\"][\"addition\"].keys()), \n",
    "        \"transcribe_text\": lambda x: \"-\".join(x[\"job\"][\"addition\"].keys()) + 'with text: ' + x[\"job\"][\"base_command\"][\"reason\"]\n",
    "    }\n",
    "\n",
    "    \n",
    "    for result_setting_key in result_settings.keys():\n",
    "        print(result_setting_key)\n",
    "        # grouped by model, score\n",
    "        grouped = group_by_key_and_sort(compare_requests, result_settings[result_setting_key],text_type)\n",
    "        grouped_data = {}\n",
    "        for key in grouped.keys():\n",
    "            stats = get_results_stats(grouped[key], text_type)\n",
    "            grouped_data[key] = stats\n",
    "        \n",
    "        \n",
    "        if result_setting_key not in result:\n",
    "            result[result_setting_key] = {}\n",
    "        \n",
    "        result[result_setting_key][text_type] = grouped_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open(research_dir+'compare_output.json', 'w') as f:\n",
    "        data = json.dump(result,f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4108\n"
     ]
    }
   ],
   "source": [
    "# create csv\n",
    "import csv\n",
    "\n",
    "rows = []\n",
    "\n",
    "print(len(compare_requests))\n",
    "\n",
    "for result in compare_requests:\n",
    "    rows.append({\n",
    "        \n",
    "        # settings\n",
    "        \"provider\": result[\"settings\"]['model']['provider'], \n",
    "        \"model\": result[\"settings\"]['model']['model_name'],\n",
    "        \"temperature\": result[\"settings\"]['temperature']['temperature'],\n",
    "        \"image\": result[\"settings\"][\"image\"]['image_name'], \n",
    "        \"base_command\": result[\"settings\"][\"job\"][\"base_command\"][\"reason\"], \n",
    "        \"addition\": \"-\".join(result[\"settings\"][\"job\"][\"addition\"].keys()), \n",
    "        \"transcribe_text\": \"-\".join(result[\"settings\"][\"job\"][\"addition\"].keys()) + \"  \" + result[\"settings\"][\"job\"][\"base_command\"][\"reason\"],\n",
    "        \n",
    "        # scores\n",
    "        \"raw_score\": result[\"scores\"][\"raw\"][\"score\"],\n",
    "        \"corrected_score\": result[\"scores\"][\"corrected\"][\"score\"],\n",
    "        \n",
    "        # changes count\n",
    "        \"raw_change_count\": len(result[\"scores\"][\"raw\"][\"changes\"]),\n",
    "        \"corrected_change_count\": len(result[\"scores\"][\"corrected\"][\"changes\"]),\n",
    "        \n",
    "        # time\n",
    "        \"delta_time_in_s\": result[\"delta_time_s\"],\n",
    "        \n",
    "        # certainty and handwriting\n",
    "        \"certainty\": result[\"result\"][\"certainty\"] if \"certainty\" in result[\"result\"] else None,\n",
    "        \"student_handwriting_percent\": result[\"result\"][\"student_handwriting_percent\"] if \"student_handwriting_percent\" in result[\"result\"] else None,\n",
    "        \n",
    "    })\n",
    "    \n",
    "keys = rows[0].keys()\n",
    "\n",
    "with open(research_dir+'compare_output.csv', 'w', newline=\"\") as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(research_dir+'compare_output.json', 'w') as f:\n",
    "    data = json.load(f)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
